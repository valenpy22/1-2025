### **Parte 1: Preguntas de Alternativa (15 preguntas)**

1. **¿Cuál de las siguientes afirmaciones sobre un **Data Lake** es correcta?**
    
    - A) Un **Data Lake** solo puede almacenar datos estructurados y transformados.
        
    - B) Un **Data Lake** permite almacenar datos en su formato original sin necesidad de procesarlos.
        
    - C) Los **Data Lakes** se utilizan exclusivamente para almacenar datos históricos.
        
    - D) Los **Data Lakes** no pueden manejar datos en tiempo real.
        
2. **¿Cuál de las siguientes opciones describe mejor el modelo de almacenamiento en un **Data Warehouse**?**
    
    - A) Los datos se almacenan en su formato original, sin transformaciones.
        
    - B) Los datos son transformados, estructurados y almacenados en un formato optimizado para consultas rápidas.
        
    - C) Los **Data Warehouses** no permiten almacenamiento de datos históricos.
        
    - D) Los **Data Warehouses** solo permiten almacenar datos no estructurados.
        
3. **En el contexto de **Apache Spark**, ¿cuál es la principal ventaja de utilizarlo en un **Data Lake**?**
    
    - A) **Apache Spark** es exclusivo para procesar datos en tiempo real y no se usa en **Data Lakes**.
        
    - B) **Apache Spark** permite realizar procesamiento distribuido de grandes volúmenes de datos a gran velocidad.
        
    - C) **Apache Spark** solo se utiliza para almacenar datos, no para procesarlos.
        
    - D) **Apache Spark** puede analizar solo datos pequeños debido a sus limitaciones de escalabilidad.
        
4. **¿Qué tipo de datos es más adecuado almacenar en un **Data Lake**?**
    
    - A) Datos exclusivamente estructurados que requieren procesamiento en tiempo real.
        
    - B) Solo datos históricos que se consultan de manera esporádica.
        
    - C) Datos estructurados, semiestructurados y no estructurados sin necesidad de transformaciones previas.
        
    - D) Datos que provienen exclusivamente de bases de datos relacionales.
        
5. **¿Cuál de las siguientes opciones sobre **Snowflake** es correcta?**
    
    - A) **Snowflake** se centra solo en almacenamiento de datos no estructurados.
        
    - B) **Snowflake** utiliza una arquitectura compartida que permite el procesamiento y almacenamiento independiente.
        
    - C) **Snowflake** está optimizado solo para consultas SQL, no soporta otros lenguajes.
        
    - D) **Snowflake** no permite escalabilidad.
        
6. **¿En qué se diferencia **Apache Hudi** de otros formatos de almacenamiento en **Data Lakes**?**
    
    - A) **Apache Hudi** solo almacena datos estructurados.
        
    - B) **Apache Hudi** permite realizar actualizaciones incrementales y gestionar transacciones ACID.
        
    - C) **Apache Hudi** no permite la actualización de datos una vez almacenados.
        
    - D) **Apache Hudi** es solo un sistema de almacenamiento en caché para datos en memoria.
        
7. **En un **Data Warehouse**, ¿cuál es el propósito de las **tablas de hechos**?**
    
    - A) Contener los datos de referencia o detalles de las entidades (clientes, productos, etc.).
        
    - B) Almacenar los datos agregados que resultan de las consultas y análisis.
        
    - C) Contener las métricas y valores clave que serán analizados.
        
    - D) No contienen datos, solo referencias a otros sistemas de bases de datos.
        
8. **¿Qué ventaja tiene **Amazon Redshift** sobre otras bases de datos en la nube como **Google BigQuery** y **Snowflake**?**
    
    - A) **Amazon Redshift** permite escalar el procesamiento y el almacenamiento de manera independiente.
        
    - B) **Amazon Redshift** está optimizado exclusivamente para almacenar datos no estructurados.
        
    - C) **Amazon Redshift** es conocido por su capacidad de realizar **consultas de baja latencia** en grandes volúmenes de datos.
        
    - D) **Amazon Redshift** solo puede manejar datos estructurados de tamaño pequeño.
        
9. **En un **Data Warehouse**, ¿qué tipo de datos se almacenan en las **tablas de dimensiones**?**
    
    - A) Datos históricos que son analizados solo periódicamente.
        
    - B) Datos de referencia y características descriptivas sobre los hechos.
        
    - C) Datos que se procesan en tiempo real, como registros de clientes activos.
        
    - D) Datos transaccionales de eventos ocurridos.
        
10. **¿Cuál es la principal ventaja de utilizar **Apache Kafka** en arquitecturas de Big Data?**
    
    - A) Permite la transmisión de grandes volúmenes de datos en tiempo real con alta disponibilidad y baja latencia.
        
    - B) Solo permite el almacenamiento de datos estructurados de manera rápida.
        
    - C) Es una plataforma para análisis de datos históricos, no en tiempo real.
        
    - D) Su propósito principal es almacenar y procesar datos de forma estática.
        
11. **¿Qué tipo de análisis es más adecuado para realizar en un **Data Lake**?**
    
    - A) Análisis de datos **en tiempo real** y grandes volúmenes de datos no estructurados o semiestructurados.
        
    - B) Análisis exclusivamente histórico, sin necesidad de procesar datos en tiempo real.
        
    - C) Análisis de datos estructurados almacenados en bases de datos relacionales.
        
    - D) Análisis sobre un número limitado de datos, generalmente solo datos históricos.
        
12. **¿Qué es un **Cubo de Datos** en un **Data Warehouse**?**
    
    - A) Un archivo que contiene datos no estructurados listos para su análisis.
        
    - B) Una estructura multidimensional que almacena datos preprocesados y agregados para consultas rápidas.
        
    - C) Una base de datos relacional que almacena datos de referencia.
        
    - D) Un sistema de almacenamiento que permite almacenar datos históricos de manera eficiente.
        
13. **¿Por qué **Azure Synapse Analytics** es útil para las organizaciones que trabajan con grandes volúmenes de datos?**
    
    - A) Ofrece integración nativa con **SQL**, **Spark** y **pipelines de datos**, lo que permite manejar grandes volúmenes de datos a través de diferentes tipos de procesamiento.
        
    - B) Es solo una herramienta de almacenamiento, no de procesamiento.
        
    - C) Solo permite realizar consultas SQL, sin integrarse con **Spark** ni otros motores de procesamiento.
        
    - D) Está diseñado para almacenamiento de datos no estructurados exclusivamente.
        
14. **¿Cuál es el principal objetivo de usar **Databricks** en un entorno de procesamiento de **Big Data**?**
    
    - A) Proporcionar un entorno colaborativo para **Apache Spark** que facilita la creación de notebooks interactivos para procesamiento de datos y machine learning.
        
    - B) Solo almacenar grandes volúmenes de datos estructurados.
        
    - C) Realizar consultas SQL de alta velocidad sobre grandes volúmenes de datos.
        
    - D) Almacenar grandes volúmenes de datos no estructurados.
        
15. **¿Cuál de las siguientes afirmaciones es cierta sobre **Apache Iceberg**?**
    
    - A) Es un sistema de almacenamiento para **Data Lakes** que permite realizar **actualizaciones incrementales** y soporta **transacciones ACID**.
        
    - B) Es una plataforma para análisis de datos en tiempo real sobre grandes volúmenes de datos no estructurados.
        
    - C) Permite almacenar únicamente datos estructurados sin soporte para transacciones.
        
    - D) Se utiliza para procesar y analizar grandes volúmenes de datos en bases de datos relacionales.
        

---

### **Parte 2: Verdadero o Falso (15 preguntas)**

1. **Los **Data Lakes** solo almacenan datos estructurados y preprocesados para análisis rápidos.**
    
    - **Falso**: Los **Data Lakes** almacenan datos **en su formato original**, sin procesarlos, y pueden manejar datos **estructurados, semiestructurados y no estructurados**.
        
2. **En un **Data Warehouse**, los datos se almacenan de manera estructurada y optimizada para consultas rápidas.**
    
    - **Verdadero**
        
3. ****Apache Spark** es ideal para procesar grandes volúmenes de datos distribuidos en un **Data Lake**.**
    
    - **Verdadero**
        
4. **Los **Data Marts** se utilizan para almacenar datos generales de la empresa y no dependen de un **Data Warehouse**.**
    
    - **Falso**: Los **Data Marts** dependen de un **Data Warehouse** y están diseñados para áreas o departamentos específicos de la empresa.
        
5. ****Snowflake** es una plataforma que ofrece escalabilidad **independiente** para almacenamiento y procesamiento de datos.**
    
    - **Verdadero**
        
6. **Los **logs de aplicaciones** se almacenan típicamente en un **Data Warehouse** debido a que son estructurados y utilizados frecuentemente.**
    
    - **Falso**: Los **logs de aplicaciones** son generalmente datos **no estructurados** y se almacenan mejor en un **Data Lake**.
        
7. **El propósito de **Apache Kafka** es almacenar grandes volúmenes de datos a largo plazo para análisis posteriores.**
    
    - **Falso**: **Apache Kafka** es una plataforma de **mensajería** en tiempo real, no para almacenamiento a largo plazo.
        
8. ****Apache Hudi** se utiliza en un **Data Lake** para realizar **actualizaciones incrementales** de grandes volúmenes de datos.**
    
    - **Verdadero**
        
9. **En un **Data Warehouse**, los datos de ventas recientes se almacenarían en una capa de almacenamiento **frío**.**
    
    - **Falso**: Los datos recientes son considerados **data caliente** y se almacenan en **almacenamiento rápido** o en la **capa caliente**.
        
10. **Los **Data Lakes** son ideales para almacenar grandes volúmenes de **Big Data** no estructurado.**
    
    - **Verdadero**
        
11. **El proceso **ETL** es más común en **Data Lakes** que en **Data Warehouses**.**
    
    - **Falso**: El proceso **ETL** es común en **Data Warehouses** para transformar y cargar datos estructurados, mientras que en **Data Lakes** se utilizan enfoques más flexibles como **ELT** (Extract, Load, Transform).
        
12. ****Azure Synapse Analytics** permite el procesamiento y análisis de datos **Big Data** mediante SQL y Spark.**
    
    - **Verdadero**
        
13. **El propósito de **Databricks** es permitir **procesamiento distribuido de datos** y **machine learning** en un entorno colaborativo.**
    
    - **Verdadero**
        
14. ****Apache Iceberg** permite realizar transacciones ACID y gestionar datos estructurados dentro de un **Data Lake**.**
    
    - **Verdadero**
        
15. **Los **Data Lakes** no requieren ningún tipo de procesamiento de datos antes de su almacenamiento y análisis.**
    
    - **Falso**: Aunque los **Data Lakes** permiten almacenar datos crudos, **muchos casos requieren procesamiento** posterior de los datos para análisis.
        

---

### **Parte 3: Preguntas de Desarrollo (3 preguntas)**

1. **Describa cómo organizaría un **Data Lake** para almacenar grandes volúmenes de datos provenientes de múltiples fuentes (como sensores, logs de servidores y archivos de texto). Mencione las herramientas y el flujo de procesamiento que implementaría.**
    
2. **Compare el manejo de **data caliente** y **data fría** en un **Data Warehouse**. ¿Qué estrategias utilizaría para asegurar un acceso rápido y económico a ambos tipos de datos?**
    
3. **Explique cómo implementaría un flujo de **ETL** utilizando **Apache Spark** en un **Data Lake**. ¿Qué procesos de transformación y herramientas utilizaría para procesar y analizar grandes volúmenes de datos?**
    

---

### **Parte 1: Preguntas de Alternativa (15 preguntas)**

1. **B) Un Data Lake permite almacenar datos en su formato original sin necesidad de procesarlos.**
    
2. **B) Los datos son transformados, estructurados y almacenados en un formato optimizado para consultas rápidas.**
    
3. **B) Apache Spark permite realizar procesamiento distribuido de grandes volúmenes de datos a gran velocidad.**
    
4. **C) Datos estructurados, semiestructurados y no estructurados sin necesidad de transformaciones previas.**
    
5. **B) Snowflake utiliza una arquitectura compartida que permite el procesamiento y almacenamiento independiente.**
    
6. **B) Apache Hudi permite realizar actualizaciones incrementales y gestionar transacciones ACID.**
    
7. **C) Contener las métricas y valores clave que serán analizados.**
    
8. **C) Amazon Redshift es conocido por su capacidad de realizar consultas de baja latencia en grandes volúmenes de datos.**
    
9. **B) Datos de referencia y características descriptivas sobre los hechos.**
    
10. **A) Permite la transmisión de grandes volúmenes de datos en tiempo real con alta disponibilidad y baja latencia.**
    
11. **A) Análisis en tiempo real de grandes volúmenes de datos no estructurados o semiestructurados.**
    
12. **B) Una estructura multidimensional que almacena datos preprocesados y agregados para consultas rápidas.**
    
13. **A) Ofrece integración nativa con SQL, Spark y pipelines de datos, lo que permite manejar grandes volúmenes de datos a través de diferentes tipos de procesamiento.**
    
14. **A) Databricks es un entorno colaborativo que facilita el trabajo en equipo a través de notebooks de Apache Spark.**
    
15. **A) Es un sistema de almacenamiento para Data Lakes que permite realizar actualizaciones incrementales y soporta transacciones ACID.**
    

---

### **Parte 2: Verdadero o Falso (15 preguntas)**

1. **Falso** - Los **Data Lakes** almacenan datos en su formato original, no solo datos estructurados.
    
2. **Verdadero**
    
3. **Falso** - **Apache Kafka** no almacena datos a largo plazo, sino que transmite datos en tiempo real.
    
4. **Verdadero**
    
5. **Falso** - El proceso **ETL** no es innecesario en un **Data Lake**. Si bien los datos se almacenan tal como son, se pueden aplicar transformaciones dentro del **Data Lake**.
    
6. **Falso** - **Apache Iceberg** optimiza el procesamiento de **datos estructurados** en un **Data Lake**, no datos no estructurados.
    
7. **Falso** - Los **Data Marts** dependen de un **Data Warehouse** para obtener sus datos.
    
8. **Falso** - **Apache Flume** ingiere datos en tiempo real, pero no realiza análisis de datos.
    
9. **Verdadero**
    
10. **Verdadero**
    
11. **Falso** - Aunque los **Data Lakes** permiten almacenar datos crudos, **muchos casos requieren procesamiento** posterior de los datos para análisis.
    
12. **Verdadero**
    
13. **Verdadero**
    
14. **Verdadero**
    
15. **Falso** - El proceso **ETL** sigue siendo necesario para transformar y preparar los datos en un **Data Lake** para su análisis.
    

---

### **Parte 3: Preguntas de Desarrollo (3 preguntas)**

1. **Responde cómo organizarías un Data Lake**:
    
    - **Ingesta de datos**: Utilizar herramientas como **Apache Kafka** o **Apache Flume** para ingerir datos desde diversas fuentes (sensores, logs de servidores, archivos de texto).
        
    - **Almacenamiento**: Almacenar los datos en su formato original en **Amazon S3** o **Azure Data Lake Storage**.
        
    - **Procesamiento**: Usar **Apache Spark** o **Databricks** para transformar, limpiar y enriquecer los datos.
        
    - **Análisis y Consumo**: Después del procesamiento, utilizar herramientas de **BI** como **Tableau** o **Power BI** para visualizar y analizar los datos.
        
2. **Comparar manejo de data caliente y data fría en un Data Warehouse**:
    
    - **Data Caliente**: Almacenar en **almacenamiento de alto rendimiento (SSDs, bases de datos en memoria)**, utilizando técnicas como **particionamiento** e **indexación** para mejorar el rendimiento de las consultas.
        
    - **Data Fría**: Almacenar en **almacenamiento de bajo costo (HDD, Amazon S3)**, utilizando técnicas como **compresión** y **archivado** para reducir costos. Los datos fríos se acceden menos y deben estar disponibles solo cuando sea necesario.
        
3. **Flujo de ETL usando Apache Spark en un Data Lake**:
    
    - **Ingesta**: Usar **Apache Kafka** para transmitir datos en tiempo real o **AWS Glue** para ingesta masiva.
        
    - **Transformación**: Utilizar **Databricks** o **Apache Spark** para transformar los datos crudos, realizando operaciones de limpieza, filtrado y agregación.
        
    - **Análisis**: Realizar consultas a través de **Apache Hive** o usar **Presto** para hacer análisis SQL sobre los datos transformados.
        
    - **Consumo**: Usar herramientas como **Tableau** o **Power BI** para consumir y visualizar los resultados.