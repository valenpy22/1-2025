### **Parte 1: Preguntas de Alternativa (15 preguntas)**

1. **¿Cuál de las siguientes afirmaciones sobre un Data Warehouse (DW) es falsa?**
    
    - A) Un Data Warehouse está optimizado para consultas complejas sobre grandes volúmenes de datos históricos.
        
    - B) En un DW, los datos se almacenan exclusivamente en un modelo relacional.
        
    - C) Los datos en un DW generalmente se almacenan en un formato no estructurado para mayor flexibilidad.
        
    - D) El proceso ETL en un DW implica la extracción, transformación y carga de datos de sistemas operacionales.
        
2. **En un **Data Lake**, ¿cuál es el principal desafío de almacenar grandes volúmenes de datos sin procesar?**
    
    - A) La dificultad para realizar consultas rápidas sin transformación previa.
        
    - B) El alto costo de almacenamiento debido a la compresión de los datos.
        
    - C) La falta de herramientas de procesamiento en tiempo real.
        
    - D) La imposibilidad de almacenar datos semiestructurados.
        
3. **¿Cuál de las siguientes tecnologías NO se utiliza para el procesamiento de datos dentro de un **Data Lake**?**
    
    - A) Apache Spark
        
    - B) Apache Flume
        
    - C) Amazon Redshift
        
    - D) Hadoop
        
4. **En un **Data Warehouse**, ¿cómo se gestionan los datos históricos?**
    
    - A) Se mantienen en la capa de almacenamiento activa para análisis en tiempo real.
        
    - B) Se almacenan en un sistema de almacenamiento de bajo costo y se integran con el análisis de datos actuales.
        
    - C) Se almacenan en tablas de hechos que están optimizadas para consultas rápidas.
        
    - D) No se almacenan, ya que solo se analizan los datos actuales.
        
5. **¿Cuál de las siguientes afirmaciones sobre **Apache Kafka** es correcta?**
    
    - A) Kafka se utiliza exclusivamente para almacenar datos históricos en un Data Lake.
        
    - B) Kafka es una plataforma de mensajería distribuida que maneja grandes volúmenes de datos en tiempo real.
        
    - C) Kafka solo es adecuado para análisis de datos estructurados en tiempo real.
        
    - D) Kafka está diseñado únicamente para procesamiento por lotes de datos.
        
6. **¿Qué característica distingue a **Snowflake** de otros sistemas de almacenamiento en la nube?**
    
    - A) Su capacidad para escalar el procesamiento y el almacenamiento de manera independiente.
        
    - B) Solo permite almacenar datos no estructurados.
        
    - C) Requiere que los datos se almacenen en formato tabular antes de cargarlos.
        
    - D) Utiliza un solo nodo para el procesamiento y almacenamiento de datos.
        
7. **¿Qué función tiene un **Cubo de Datos** en un **Data Warehouse**?**
    
    - A) Almacenar datos sin procesar para su posterior análisis.
        
    - B) Agregar datos a nivel de hechos para mejorar el rendimiento de las consultas analíticas.
        
    - C) Realizar la integración de datos en un **Data Lake**.
        
    - D) Transformar los datos para su posterior carga en el **Data Warehouse**.
        
8. **¿Cuál es la principal ventaja de utilizar **Apache Hudi** sobre otros sistemas de almacenamiento en **Data Lakes**?**
    
    - A) Soporta transacciones ACID y actualizaciones incrementales de datos en tiempo real.
        
    - B) Almacena datos de manera comprimida para reducir los costos de almacenamiento.
        
    - C) Solo maneja datos estructurados para su almacenamiento.
        
    - D) Realiza procesamiento en memoria para mejorar la velocidad de las consultas.
        
9. **En el contexto de **Azure Synapse Analytics**, ¿cuál es su principal característica?**
    
    - A) Es una plataforma de análisis de Big Data que se especializa en **SQL** y **Spark**.
        
    - B) Solo almacena datos históricos para análisis a largo plazo.
        
    - C) Se enfoca exclusivamente en análisis de datos en tiempo real sin almacenamiento en la nube.
        
    - D) Su principal función es la visualización de datos, no el procesamiento.
        
10. **¿Qué tipo de datos maneja **Apache Iceberg** dentro de un **Data Lake**?**
    
    - A) Solo datos estructurados y procesados.
        
    - B) Datos históricos con soporte para transacciones ACID.
        
    - C) Datos no estructurados que requieren transformación antes de ser procesados.
        
    - D) Datos agregados para la optimización de consultas.
        
11. **¿Por qué los **Data Lakes** son considerados más flexibles que los **Data Warehouses**?**
    
    - A) Porque solo almacenan datos estructurados y preprocesados.
        
    - B) Porque almacenan datos en su formato original y permiten analizar cualquier tipo de datos (estructurados, semiestructurados y no estructurados).
        
    - C) Porque se enfocan solo en análisis históricos de datos.
        
    - D) Porque no requieren procesamiento de datos antes de almacenarlos.
        
12. **¿Cuál es el principal objetivo de **Apache Flume** en una arquitectura de procesamiento de datos distribuida?**
    
    - A) Ingerir grandes volúmenes de datos en tiempo real y transportarlos a sistemas de procesamiento como **Hadoop** o **Kafka**.
        
    - B) Analizar grandes volúmenes de datos no estructurados.
        
    - C) Almacenar datos estructurados en un **Data Warehouse**.
        
    - D) Realizar consultas en tiempo real sobre grandes volúmenes de datos.
        
13. **¿Qué diferencia a **Databricks** de otras plataformas de procesamiento de datos como **Hadoop** o **Spark**?**
    
    - A) **Databricks** es un entorno colaborativo que facilita el trabajo en equipo a través de **notebooks** de **Apache Spark**.
        
    - B) **Databricks** solo permite el procesamiento de datos estructurados.
        
    - C) **Databricks** almacena datos sin procesar en su formato nativo.
        
    - D) **Databricks** es un servicio exclusivamente para almacenamiento de datos.
        
14. **¿Qué tipo de consultas son más rápidas en un **Data Warehouse** cuando se utiliza un modelo dimensional?**
    
    - A) Consultas con múltiples joins complejos entre grandes volúmenes de datos.
        
    - B) Consultas simples con un solo filtro sobre tablas de hechos.
        
    - C) Consultas de agregación sobre grandes volúmenes de datos sin transformación previa.
        
    - D) Consultas sobre datos no estructurados almacenados en un **Data Lake**.
        
15. **¿Qué tipo de análisis es ideal para realizar con un **Data Lake**?**
    
    - A) Análisis de datos históricos preprocesados.
        
    - B) Análisis en tiempo real de grandes volúmenes de datos no estructurados.
        
    - C) Análisis de datos transaccionales estructurados.
        
    - D) Análisis de datos predicciones a corto plazo sobre datos estructurados.
        

---

### **Parte 2: Verdadero o Falso (15 preguntas)**

1. **Un **Data Lake** almacena solo datos estructurados para facilitar su análisis en tiempo real.**
    
    - **Falso**: Los **Data Lakes** almacenan datos estructurados, semiestructurados y no estructurados, permitiendo mayor flexibilidad en el tipo de datos.
        
2. **En un **Data Warehouse**, los datos se transforman y se almacenan en un formato estructurado y optimizado para consultas rápidas.**
    
    - **Verdadero**
        
3. **El principal propósito de **Apache Kafka** es almacenar grandes volúmenes de datos a largo plazo para su análisis posterior.**
    
    - **Falso**: **Apache Kafka** es una plataforma de mensajería distribuida, no se utiliza para almacenamiento a largo plazo, sino para transmitir datos en tiempo real.
        
4. **Los **Data Marts** en un **Data Warehouse** se utilizan para almacenar subconjuntos de datos relevantes para departamentos o áreas de negocio específicos.**
    
    - **Verdadero**
        
5. **El proceso de **ETL** es innecesario en un **Data Lake**, ya que los datos se almacenan tal como son.**
    
    - **Verdadero** (Aunque algunos **procesos ETL** pueden usarse en la capa de procesamiento en un **Data Lake**, los datos se almacenan sin procesar en su formato original).
        
6. ****Apache Iceberg** es una herramienta que optimiza el procesamiento de datos no estructurados en un **Data Lake**.**
    
    - **Falso**: **Apache Iceberg** es una solución de almacenamiento en **Data Lakes** que optimiza el manejo de datos estructurados y permite transacciones ACID.
        
7. **El propósito principal de **Databricks** es almacenar grandes volúmenes de datos no estructurados.**
    
    - **Falso**: **Databricks** es una plataforma de procesamiento de datos que integra **Apache Spark** para análisis y machine learning, pero no está enfocada en almacenar datos no estructurados.
        
8. **En un **Data Warehouse**, los datos históricos son generalmente almacenados en tablas de hechos y dimensiones para su análisis posterior.**
    
    - **Verdadero**
        
9. ****Snowflake** se distingue por su capacidad para escalar el almacenamiento y el procesamiento de manera independiente.**
    
    - **Verdadero**
        
10. **El uso de un **Data Lake** elimina la necesidad de realizar cualquier tipo de procesamiento de datos.**
    
    - **Falso**: Aunque los **Data Lakes** permiten almacenar datos sin procesarlos inicialmente, los datos generalmente deben ser procesados más adelante para ser útiles.
        
11. **En un **Data Warehouse**, los datos de ventas recientes serían almacenados en la capa de almacenamiento frío.**
    
    - **Falso**: Los datos de ventas recientes se consideran **data caliente** y se almacenan en particiones de alto rendimiento para acceso rápido.
        
12. **La principal ventaja de **Apache Hudi** es que permite realizar actualizaciones incrementales sobre grandes volúmenes de datos almacenados en un **Data Lake**.**
    
    - **Verdadero**
        
13. **Los **Data Marts** son siempre independientes de un **Data Warehouse** y no dependen de este para obtener sus datos.**
    
    - **Falso**: Los **Data Marts** generalmente se alimentan de un **Data Warehouse** para proporcionar datos específicos a un área o departamento.
        
14. **El propósito de **Apache Flume** es realizar análisis de datos no estructurados en tiempo real.**
    
    - **Falso**: **Apache Flume** se usa principalmente para la **ingesta de datos** en tiempo real, no para su análisis.
        
15. **En un **Data Warehouse**, los datos se transforman antes de ser cargados para garantizar que sean consistentes y estén listos para su análisis.**
    
    - **Verdadero**
        

---

### **Parte 3: Preguntas de Desarrollo (3 preguntas)**

1. **Describa cómo gestionaría la integración de datos en un **Data Lake**. Mencione los pasos clave y las herramientas que utilizaría para procesar datos crudos y hacerlos accesibles para análisis posteriores.**
    
2. **Compare las estrategias de manejo de **data caliente** y **data fría** en un **Data Warehouse**. ¿Qué técnicas utilizaría para optimizar el almacenamiento y rendimiento de ambos tipos de datos?**
    
3. **Imagine que está implementando un **Data Lake** para una empresa que tiene datos de ventas, registros de clientes y logs de aplicaciones. Explique cómo organizaría el almacenamiento de estos datos en el Data Lake, y qué procesos de procesamiento implementaría para analizarlos de manera eficiente.**

### **Parte 1: Preguntas de Alternativa (15 preguntas)**

1. **C) Los datos en un Data Warehouse generalmente se almacenan en un formato no estructurado para mayor flexibilidad.**
    
2. **A) La dificultad para realizar consultas rápidas sin transformación previa.**
    
3. **C) Amazon Redshift**
    
4. **B) Se almacenan en un sistema de almacenamiento de bajo costo y se integran con el análisis de datos actuales.**
    
5. **B) Kafka es una plataforma de mensajería distribuida que maneja grandes volúmenes de datos en tiempo real.**
    
6. **A) Su capacidad para escalar el procesamiento y el almacenamiento de manera independiente.**
    
7. **B) Agregar datos a nivel de hechos para mejorar el rendimiento de las consultas analíticas.**
    
8. **A) Soporta transacciones ACID y actualizaciones incrementales de datos en tiempo real.**
    
9. **A) Es una plataforma de análisis de Big Data que se especializa en SQL y Spark.**
    
10. **B) Datos estructurados con soporte para transacciones ACID.**
    
11. **B) Porque almacenan datos en su formato original y permiten analizar cualquier tipo de datos (estructurados, semiestructurados y no estructurados).**
    
12. **A) Ingerir grandes volúmenes de datos en tiempo real y transportarlos a sistemas de procesamiento como Hadoop o Kafka.**
    
13. **A) Databricks es un entorno colaborativo que facilita el trabajo en equipo a través de notebooks de Apache Spark.**
	
14. **B) Consultas simples con un solo filtro sobre tablas de hechos.**
	
15.  **B) Análisis en tiempo real de grandes volúmenes de datos no estructurados.**
	
---

### **Parte 2: Verdadero o Falso (15 preguntas)**

1. **Falso** - Los Data Lakes almacenan datos en su formato original, no solo datos estructurados.
    
2. **Verdadero**
    
3. **Falso** - Apache Kafka no almacena datos a largo plazo, sino que transmite datos en tiempo real.
    
4. **Verdadero**
    
5. **Falso** - El proceso de ETL no es innecesario en un Data Lake. Si bien los datos se almacenan tal como son, se pueden aplicar transformaciones dentro del Data Lake.
    
6. **Falso** - Apache Iceberg optimiza el procesamiento de **datos estructurados** en un Data Lake, no datos no estructurados.
    
7. **Falso** - Los Data Marts dependen de un Data Warehouse para obtener sus datos.
    
8. **Falso** - Apache Flume ingiere datos en tiempo real, pero no realiza análisis de datos.
    
9. **Verdadero**
    

---

### **Parte 3: Preguntas de Desarrollo (3 preguntas)**

1. **La respuesta debe mencionar la ingesta de datos mediante herramientas como Apache Kafka o Flume, el almacenamiento de datos en su formato nativo (como JSON, CSV, Parquet), el procesamiento de datos con herramientas como Databricks o Apache Spark, y el análisis y consumo de datos mediante plataformas de BI como Tableau o Power BI.**
    
2. **La respuesta debe incluir estrategias de almacenamiento de datos calientes en sistemas de alto rendimiento (discos SSD, bases de datos en memoria) y datos fríos en almacenamiento económico (HDD, Amazon S3, Glacier). Técnicas de optimización incluyen particionamiento de datos y compresión para datos fríos, y el uso de caché e índices para datos calientes.**
    
3. **La respuesta debe mencionar la ingesta de datos crudos desde diferentes fuentes (bases de datos, logs, etc.), el almacenamiento en carpetas correspondientes (ventas, clientes, logs) en formatos adecuados, el procesamiento de los datos con herramientas como Databricks para transformarlos y analizarlos, y el uso de herramientas de BI para el consumo y visualización de los datos procesados.**